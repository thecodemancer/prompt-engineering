{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN5410TOQaqjrAmtrmLw+Z7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thecodemancer/prompt-engineering/blob/main/prompt_design_strategies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt design strategies"
      ],
      "metadata": {
        "id": "qYArCg8ZN7t3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt design enables users who are new to machine learning (ML) control model output with minimal overhead. By carefully crafting prompts, you can nudge the model to generate a desired result. Prompt design is an efficient way to experiment with adapting a language model for a specific use case.\n",
        "\n",
        "Language models, especially large language models (LLM), are trained on vast amounts of text data to learn the patterns and relationships between words. When given some text (the prompt), language models can predict what is likely to come next, like a sophisticated autocompletion tool. Therefore, when designing prompts, consider the different factors that can influence what a model predicts comes next.\n",
        "\n",
        "While there's no right or wrong way to design a prompt, there are common strategies that you can use to affect the model's responses. This section introduces you to some common prompt design strategies.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s2Ir8jzSpqNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Give clear instructions\n",
        "Craft user-friendly prompts to subtly steer powerful language models for specific tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "NPv7kIe8MsLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giving the model instructions means telling the model what to do. This strategy can be an effective way to customize model behavior. Ensure that the instructions you give are clear and concise.\n",
        "\n",
        "The following prompt provides a block of text and tells the model to summarize it:\n",
        "\n",
        "**Prompt**\n",
        "\n",
        "```\n",
        "Summarize this text.\n",
        "Text: A quantum computer exploits quantum mechanical phenomena to perform\n",
        "calculations exponentially faster than any modern traditional computer. At very\n",
        "tiny scales, physical matter acts as both particles and as waves, and quantum\n",
        "computing uses specialized hardware to leverage this behavior. The operating\n",
        "principles of quantum devices is beyond the scope of classical physics. When\n",
        "deployed at scale, quantum computers could be used in a wide variety of\n",
        "applications such as: in cybersecurity to break existing encryption methods\n",
        "while helping researchers create new ones, in meteorology to develop better\n",
        "weather forecasting etc. However, the current state of the art quantum\n",
        "computers are still largely experimental and impractical.\n",
        "```"
      ],
      "metadata": {
        "id": "yoIgFUxPNJY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Response:**\n",
        "```\n",
        "A quantum computer is a device that uses quantum mechanics to perform\n",
        "calculations. It can perform calculations exponentially faster than any modern\n",
        "traditional computer. Quantum computers use specialized hardware to leverage the\n",
        "behavior of physical matter at very tiny scales. This behavior is beyond the\n",
        "scope of classical physics. When deployed at scale, quantum computers could be\n",
        "used in a wide variety of applications. These include cybersecurity,\n",
        "meteorology, and drug discovery. However, the current state of the art quantum\n",
        "computers are still largely experimental and impractical.\n",
        "```"
      ],
      "metadata": {
        "id": "VVSgqWLqNWkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model provided a concise summary, but maybe you want the summary to be written in a way that's easier to understand. For example, the following prompt includes an instruction to write a summary that's simple enough for a fifth grader to understand:"
      ],
      "metadata": {
        "id": "j-OjQSFPNf3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt:\n",
        "\n",
        "```\n",
        "Summarize this text. Write the summary so that a fifth grader can understand it.\n",
        "Text: A quantum computer exploits quantum mechanical phenomena to perform\n",
        "calculations exponentially faster than any modern traditional computer. At very\n",
        "tiny scales, physical matter acts as both particles and as waves, and quantum\n",
        "computing uses specialized hardware to leverage this behavior. The operating\n",
        "principles of quantum devices is beyond the scope of classical physics. When\n",
        "deployed at scale, quantum computers could be used in a wide variety of\n",
        "applications such as: in cybersecurity to break existing encryption methods\n",
        "while helping researchers create new ones, in meteorology to develop better\n",
        "weather forecasting etc. However, the current state of the art quantum\n",
        "computers are still largely experimental and impractical.\n",
        "```"
      ],
      "metadata": {
        "id": "BAWHvMcwNk8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response:\n",
        "```\n",
        "A quantum computer is a new kind of computer that uses different rules than\n",
        "regular computers. It can do some calculations much faster than regular\n",
        "computers. Quantum computers are still being developed, but they could be used\n",
        "for things like breaking codes and weather forecasting.\n",
        "  \n",
        "```"
      ],
      "metadata": {
        "id": "-OBOiMtHNrfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The instruction to write the summary so a fifth grader can understand it resulted in a response that's easier to understand.\n",
        "\n",
        "**Summary:**\n",
        "\n",
        "- Give the models instructions to customize its behavior.\n",
        "- Make each instruction clear and concise."
      ],
      "metadata": {
        "id": "qc6ck5XvNw5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Include examples\n",
        "You can include examples in the prompt that show the model what getting it right looks like. The model attempts to identify patterns and relationships from the examples and apply them to form a response. Prompts that contain a few examples are called *few-shot prompts*, while prompts that provide no examples are called *zero-shot prompts*. *Few-shot prompts* are often used to regulate the formatting, phrasing, scoping, or general patterning of model responses.\n",
        "\n",
        "**Zero-shot vs few-shot prompts**\n",
        "\n",
        "The following zero-shot prompt asks the model to choose the best explanation.\n",
        "\n",
        "**Prompt**\n",
        "```\n",
        "Please choose the best explanation to the question:\n",
        "Question: How is snow formed?\n",
        "Explanation1: Snow is formed when water vapor in the air freezes into ice crystals in the atmosphere,\n",
        "which can combine and grow into snowflakes as they fall through the atmosphere and accumulate on the ground.\n",
        "Explanation2: Water vapor freezes into ice crystals forming snow.\n",
        "Answer:\n",
        "```  \n"
      ],
      "metadata": {
        "id": "NYpbnuGWMtzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Response:**\n",
        "```\n",
        "Explanation1\n",
        "```"
      ],
      "metadata": {
        "id": "hL2tGVPxQkO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your use case requires the model to produce concise responses, you can include examples in the prompt that give preference to concise responses.\n",
        "\n",
        "The following prompt provides two examples that show preference to the shorter explanations. In the response, you can see that the examples guided the model to choose the shorter explanation (Explanation2) as opposed to the longer explanation (Explanation1) like it did previously."
      ],
      "metadata": {
        "id": "v6_9p9inQzd8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt***\n",
        "\n",
        "```\n",
        "Please choose the best explanation to the question:\n",
        "\n",
        "Question: Why is sky blue?\n",
        "Explanation1: The sky appears blue because of Rayleigh scattering, which causes shorter blue wavelengths of light to be scattered more easily than longer red wavelengths, making the sky look blue.\n",
        "Explanation2: Due to Rayleigh scattering effect.\n",
        "Answer: Explanation2, because Explanation2 is shorter.\n",
        "\n",
        "Question: What is the cause of earthquakes?\n",
        "Explanation1: Sudden release of energy in the Earth's crust.\n",
        "Explanation2: Earthquakes happen when tectonic plates suddenly slip or break apart, causing a release of energy that creates seismic waves that can shake the ground and cause damage.\n",
        "Answer: Explanation1, because Explanation1 is shorter.\n",
        "\n",
        "Question: How is snow formed?\n",
        "Explanation1: Snow is formed when water vapor in the air freezes into ice crystals in the atmosphere, which can combine and grow into snowflakes as they fall through the atmosphere and accumulate on the ground.\n",
        "Explanation2: Water vapor freezes into ice crystals forming snow.\n",
        "Answer:\n",
        "```"
      ],
      "metadata": {
        "id": "_swr4lqqQ30U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Find the optimal number of examples**\n",
        "\n",
        "You can experiment with the number of examples to provide in the prompt for the most desired results. Models like PaLM can often pick up on patterns using a few examples, though you may need to experiment with what number of examples lead to the desired results. For simpler models like BERT, you may need more examples. At the same time, if you include too many examples, the model may start to overfit the response to the examples.\n",
        "\n",
        "**Use examples to show patterns instead of antipatterns**\n",
        "\n",
        "Using examples to show the model a pattern to follow is more effective than using examples to show the model an antipattern to avoid.\n",
        "\n",
        "⛔ **Negative pattern:**"
      ],
      "metadata": {
        "id": "Ae_pP-a3X_Do"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt**\n",
        "```\n",
        "Don't end haikus with a question:\n",
        "Haiku are fun\n",
        "A short and simple poem\n",
        "Don't you enjoy them?\n",
        "```  "
      ],
      "metadata": {
        "id": "eX9aiuo2Ygay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ **Positive pattern:**\n",
        "\n",
        "**Prompt**\n",
        "```\n",
        "Always end haikus with an assertion:\n",
        "Haiku are fun\n",
        "A short and simple poem\n",
        "A joy to write\n",
        "```"
      ],
      "metadata": {
        "id": "xuTfrn_eYvPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary:**\n",
        "\n",
        "- Including prompt-response examples in the prompt helps the model learn how to respond.\n",
        "- Give the model examples of the patterns to follow instead of examples of patterns to avoid.\n",
        "- Experiment with the number of prompts to include. Depending on the model, too few examples are ineffective at changing model behavior. Too many examples cause the model to overfit."
      ],
      "metadata": {
        "id": "DOEvGZmDY-ZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let the model complete partial input\n",
        "\n",
        "Generative language models work like an advanced autocompletion tool. When you provide partial content, the model can provide the rest of the content or what it thinks is a continuation of that content as a response. When doing so, if you include any examples or context, the model can take those examples or context into account.\n",
        "\n",
        "The following example provides a prompt with an instruction and an entity input:\n",
        "\n",
        "**Prompt**\n",
        "```\n",
        "For the given order, return a JSON object that has the fields cheeseburger, burger, fries, or drink,\n",
        "with the value being the quantity.\n",
        "\n",
        "Order: A burger and a drink.\n",
        "```"
      ],
      "metadata": {
        "id": "ugZTxZy7MvQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Response**\n",
        "\n",
        "```\n",
        "Sure, here is the JSON object that you requested:\n",
        "\n",
        "json\n",
        "{\n",
        "  \"burger\": 1,\n",
        "  \"drink\": 1\n",
        "}\n",
        "\n",
        "I hope this is helpful!\n",
        "```"
      ],
      "metadata": {
        "id": "tdKYejtSZrD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the model did as prompted, writing out the instructions in natural language can sometimes be challenging. In this case, you can give an example and a response prefix and let the model complete it:\n",
        "\n",
        "**Prompt**\n",
        "\n",
        "```\n",
        "Valid fields are cheeseburger, hamburger, fries, and drink.\n",
        "Order: Give me a cheeseburger and fries\n",
        "Output: {\"cheeseburger\": 1, \"fries\": 1}\n",
        "\n",
        "Order: I want two burgers, a drink, and waffles.\n",
        "Output:\n",
        "  \n",
        "  ```"
      ],
      "metadata": {
        "id": "dlM8RwJBZ44t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Response**\n",
        "```\n",
        "{\"hamburger\": 2, \"drink\": 1}\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "ejaUI4Oaawca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how \"waffles\" was excluded from the output because it wasn't listed in the context as a valid field.\n",
        "\n"
      ],
      "metadata": {
        "id": "Tse_h_6tbO-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt the model to format its response\n",
        "The completion strategy can also help format the response. The following example prompts the model to create an essay outline:\n",
        "\n",
        "**Prompt**\n",
        "```\n",
        "**Create an outline for an essay about hummingbirds.\n",
        "\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "Hummingbirds are the smallest birds in the world, and they are also one of the most fascinating. They are found in North and South America, and they are known for their long, thin beaks and their ability to fly at high speeds.\n",
        "\n",
        "**Body**\n",
        "\n",
        "Hummingbirds are made up of three main parts: the head, the body, and the tail. The head is small and round, and it contains the eyes, the beak, and the brain. The body is long and slender, and it contains the wings, the legs, and the heart. The tail is long and forked, and it helps the hummingbird to balance while it is flying.\n",
        "\n",
        "Hummingbirds are also known for their coloration. They come in a variety of colors, including green, blue, red, and purple. Some hummingbirds are even able to change their color!\n",
        "\n",
        "Hummingbirds are very active creatures. They spend most of their time flying, and they are also very good at hovering. Hummingbirds need to eat a lot of food in order to maintain their energy, and they often visit flowers to drink nectar.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Hummingbirds are amazing creatures. They are small, but they are also very powerful. They are beautiful, and they are very important to the ecosystem.\n",
        "\n",
        "**Hummingbird Facts**\n",
        "\n",
        "* Hummingbirds are the smallest birds in the world.\n",
        "* Hummingbirds are found in North and South America.\n",
        "* Hummingbirds are known for their long, thin beaks and their ability to fly at high speeds.\n",
        "* Hummingbirds are made up of three main parts: the head, the body, and the tail.\n",
        "* Hummingbirds are also known for their coloration.\n",
        "* Hummingbirds are very active creatures.\n",
        "* Hummingbirds need to eat a lot of food in order to maintain their energy.\n",
        "* Hummingbirds are very important to the ecosystem.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "UO1v_QwZMww7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prompt didn't specify the format for the outline and the model chose a format for you. To get the model to return an outline in a specific format, you can add text that represents the start of the outline and let the model complete it based on the pattern that you initiated.\n",
        "\n",
        "**Prompt**\n",
        "\n",
        "```\n",
        "Create an outline for an essay about hummingbirds.\n",
        "I. Introduction\n",
        "```"
      ],
      "metadata": {
        "id": "Z4OCvR_VcmIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Response\n",
        "\n",
        "```Hummingbirds are the smallest birds in the world.\n",
        "   * They are found in North and South America.\n",
        "   * They are attracted to flowers because of the nectar they provide.\n",
        "   * Hummingbirds are very fast and can fly up to 20 miles per hour.\n",
        "   * They are also very good at hovering in mid-air.\n",
        "\n",
        "II. Body\n",
        "   * Hummingbirds have a long, thin body with a short neck and a large head.\n",
        "   * They have a long, pointed bill that is used for drinking nectar from flowers.\n",
        "   * They have wings that are very fast and can beat up to 80 times per second.\n",
        "   * They have a long tail that is used for balance.\n",
        "   * Hummingbirds come in many different colors, but the most common colors are #188038, blue, and red.\n",
        "\n",
        "III. Conclusion\n",
        "   * Hummingbirds are amazing creatures that are a joy to watch.\n",
        "   * They are very important to the ecosystem because they help to pollinate flowers.\n",
        "   * They are also a popular tourist attraction because of their beauty and speed.\n",
        "\n",
        "IV. Hummingbird Facts\n",
        "   * Hummingbirds are the smallest birds in the world, with some species measuring only as long as a dime.\n",
        "   * They are found in North and South America, and they can be found in a variety of habitats, including forests, deserts, and even urban areas.\n",
        "   * Hummingbirds are attracted to flowers because of the nectar they provide, and they are often seen hovering in mid-air as they drink from flowers.\n",
        "   * Hummingbirds are very fast, and they can fly up to 20 miles per hour.\n",
        "   * They are also very good at hovering in mid-air, and they can even fly backwards!\n",
        "   * Hummingbirds are important pollinators, and they help to spread pollen from flower to flower.\n",
        "   * They are also a popular tourist attraction, and people love to watch them as they fly around and drink from flowers.\n",
        "\n",
        "V. Hummingbird Care\n",
        "   * Hummingbirds are not difficult to care for, but there are a few things you need to do to keep them healthy.\n",
        "   * First, you need to provide them with a place to live. This can be a birdhouse or a hummingbird feeder.\n",
        "   * You also need to provide them with food. Hummingbirds eat nectar, so you can buy hummingbird nectar at most pet stores.\n",
        "   * You also need to keep the birdhouse or feeder clean.\n",
        "   * Finally, you need to protect the hummingbirds from predators. This can be done by putting a net around the birdhouse or feeder.\n",
        "\n",
        "VI. Hummingbird Conservation\n",
        "   * Hummingbirds are important pollinators, and they help to spread pollen from flower to flower.\n",
        "   * They are also a popular tourist attraction, and people love to watch them as they fly around and drink from flowers.\n",
        "   * However, hummingbirds are facing a number of threats, including habitat loss, climate change, and pesticides.\n",
        "   * We can all help to conserve hummingbirds by planting native plants, avoiding pesticides, and supporting hummingbird conservation organizations.\n",
        "```"
      ],
      "metadata": {
        "id": "sR2ztG7wc4E3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Summary:***\n",
        "\n",
        "- If you give the model a partial input, the model completes that input based on any available examples or context in the prompt.\n",
        "- Having the model complete an input may sometimes be easier than describing the task in natural language.\n",
        "- Adding a partial answer to a prompt can guide the model to follow a desired pattern or format."
      ],
      "metadata": {
        "id": "78BYVwApdeq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add contextual information\n",
        "You can include in the prompt instructions and information that the model needs to solve a problem instead of assuming that the model has all of the required information.\n",
        "\n",
        "The following example asks the model to give troubleshooting guidance for a router:\n"
      ],
      "metadata": {
        "id": "KkycIqSTMyAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt**\n",
        "```\n",
        "What should I do to fix my disconnected wifi? The light on my Google Wifi router is yellow and blinking slowly.\n",
        "```\n"
      ],
      "metadata": {
        "id": "JvugRaohds12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Response**\n",
        "\n",
        "```\n",
        "There are a few things you can do to try to fix your disconnected WiFi when the light on your Google Wifi router is yellow and blinking slowly.\n",
        "\n",
        "1. Check your internet connection. Make sure that your modem is turned on and that the cable is properly connected to the router. You can also try restarting your modem.\n",
        "2. Check your WiFi connection. Make sure that your WiFi is turned on and that you are within range of your router. You can also try restarting your WiFi.\n",
        "3. Move your router to a different location. Make sure that your router is not in a location where it is blocked by walls or other objects.\n",
        "4. Update your router's firmware. You can update your router's firmware by going to the Google Wifi website and following the instructions.\n",
        "5. Factory reset your router. If you are still having problems, you can factory reset your router. This will erase all of your settings and you will need to set it up again from scratch.\n",
        "\n",
        "To factory reset your router, you will need to log into the Google Wifi app and go to the Settings menu. Then, select the Advanced tab and click on the Factory Reset button. You will need to confirm that you want to factory reset your router. Once the reset is complete, you will need to set it up again from scratch.\n",
        "\n",
        "If you are still having problems after trying these steps, you can contact Google support for help.\n",
        "```"
      ],
      "metadata": {
        "id": "XeAeJibid7WX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The response looks like generic troubleshooting information that's not specific to the router or the status of the LED indicator lights.\n",
        "\n",
        "To customize the response for the specific router, you can add to the prompt the router's troubleshooting guide as context for it to refer to when providing a response.\n"
      ],
      "metadata": {
        "id": "05-cdaqUeM-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt**\n",
        "\n",
        "```\n",
        "Answer the question using the text below. Respond with only the text provided.\n",
        "Question: What should I do to fix my disconnected wifi? The light on my Google Wifi router is yellow and blinking slowly.\n",
        "\n",
        "Text:\n",
        "Color: Slowly pulsing yellow\n",
        "What it means: There is a network error.\n",
        "What to do:\n",
        "Check that the Ethernet cable is connected to both your router and your modem and both devices are turned on. You might need to unplug and plug in each device again.\n",
        "\n",
        "Color: Fast blinking yellow\n",
        "What it means: You are holding down the reset button and are factory resetting this device.\n",
        "What to do:\n",
        "If you keep holding down the reset button, after about 12 seconds, the light will turn solid yellow. Once it is solid yellow, let go of the factory reset button.\n",
        "\n",
        "Color: Solid yellow\n",
        "What it means: Router is factory resetting.\n",
        "What to do:\n",
        "This can take up to 10 minutes. When it's done, the device will reset itself and start pulsing white, letting you know it's ready for setup.\n",
        "\n",
        "Color: Solid red\n",
        "What it means: Something is wrong.\n",
        "What to do:\n",
        "Critical failure. Factory reset the router. If the light stays red, contact Wifi customer support.\n",
        "```\n",
        "\n",
        "**Response**\n",
        "\n",
        "```\n",
        "It seems like your Google Wifi router is having a network error. According to the text, you should check that the Ethernet cable is connected to both your router and your modem and both devices are turned on. You might need to unplug and plug in each device again.\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "NKZBAAQaeZeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary:**\n",
        "\n",
        "- Include information (context) in the prompt that you want the model to use when generating a response.\n",
        "- Give the model instructions on what to do."
      ],
      "metadata": {
        "id": "MH5fPRSBelF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add prefixes\n",
        "\n",
        "A prefix is a word or phrase that you add to the prompt content that can serve several purposes, depending on where you put the prefix:\n",
        "\n",
        "**Input prefix:** Adding a prefix to the input signals semantically meaningful parts of the input to the model. For example, the prefixes \"English:\" and \"French:\" demarcate two different languages.\n",
        "\n",
        "**Output prefix:** Even though the output is generated by the model, you can add a prefix for the output in the prompt. The output prefix gives the model information about what's expected as a response. For example, the output prefix \"JSON:\" signals to the model that the output should be in JSON format.\n",
        "\n",
        "**Example prefix:** In few-shot prompts, adding prefixes to the examples provide labels that the model can use when generating the output, which makes it easier to parse output content.\n",
        "\n",
        "In the following example, \"Text:\" is the input prefix and \"The answer is:\" is the output prefix."
      ],
      "metadata": {
        "id": "Do6eMrYmMzHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt**\n",
        "```\n",
        "Classify the text as one of the following categories.\n",
        "- large\n",
        "- small\n",
        "Text: Rhino\n",
        "The answer is: large\n",
        "Text: Mouse\n",
        "The answer is: small\n",
        "Text: Snail\n",
        "The answer is: small\n",
        "Text: Elephant\n",
        "The answer is:\n",
        "```\n",
        "\n",
        "**Response**\n",
        "```\n",
        "large\n",
        "```"
      ],
      "metadata": {
        "id": "1orYfTKHfLcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment with different parameter values\n",
        "\n",
        "Each call that you send to a model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. Experiment with different parameter values to get the best values for the task. The parameters available for different models may differ. The most common parameters are the following:\n",
        "\n",
        "- Max output tokens\n",
        "- Temperature\n",
        "- Top-K\n",
        "- Top-P\n"
      ],
      "metadata": {
        "id": "ksAssgIyM0Jt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Max output tokens\n",
        "Maximum number of tokens that can be generated in the response. A token is approximately four characters. 100 tokens correspond to roughly 60-80 words.\n",
        "Specify a lower value for shorter responses and a higher value for longer responses."
      ],
      "metadata": {
        "id": "DIdYRm1IjsIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperature\n",
        "The temperature is used for sampling during response generation, which occurs when `topP` and `topK` are applied. Temperature controls the degree of randomness in token selection. Lower temperatures are good for prompts that require a more deterministic and less open-ended or creative response, while higher temperatures can lead to more diverse or creative results. A temperature of `0` is deterministic, meaning that the highest probability response is always selected.\n",
        "For most use cases, try starting with a temperature of `0.2`. If the model returns a response that's too generic, too short, or the model gives a fallback response, try increasing the temperature."
      ],
      "metadata": {
        "id": "XofOJnZ_j16o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top-K\n",
        "Top-K changes how the model selects tokens for output. A top-K of `1` means the next selected token is the most probable among all tokens in the model's vocabulary (also called greedy decoding), while a top-K of `3` means that the next token is selected from among the three most probable tokens by using temperature.\n",
        "For each token selection step, the top-K tokens with the highest probabilities are sampled. Then tokens are further filtered based on top-P with the final token selected using temperature sampling.\n",
        "\n",
        "Specify a lower value for less random responses and a higher value for more random responses. The default top-K is `40`."
      ],
      "metadata": {
        "id": "vaHHjizgj5AB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top-P\n",
        "Top-P changes how the model selects tokens for output. Tokens are selected from the most (see `top-K`) to least probable until the sum of their probabilities equals the top-P value. For example, if tokens A, B, and C have a probability of 0.3, 0.2, and 0.1 and the top-P value is `0.5`, then the model will select either A or B as the next token by using temperature and excludes C as a candidate.\n",
        "Specify a lower value for less random responses and a higher value for more random responses. The default top-P is 0.95."
      ],
      "metadata": {
        "id": "PT_d-fpcj6_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt iteration strategies\n",
        "Prompt design is an iterative process that often requires a few iterations before you get the desired response consistently. This section provides guidance on some things you can try when iterating on your prompts."
      ],
      "metadata": {
        "id": "tPcwMYIdM1tK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use different phrasing\n",
        "Using different words or phrasing in your prompts often yield different responses from the model even though they all mean the same thing. If you're not getting the expected results from your prompt, try rephrasing it.\n",
        "\n",
        "```\n",
        "Version 1:\n",
        "How do I bake a pie?\n",
        "\n",
        "Version 2:\n",
        "Suggest a recipe for a pie.\n",
        "\n",
        "Version 3:\n",
        "What's a good pie recipe?\n",
        "```"
      ],
      "metadata": {
        "id": "x2uq6xabg_5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Switch to an analogous task\n",
        "If you can't get the model to follow your instructions for a task, try giving it instructions for an analogous task that achieves the same result.\n",
        "\n",
        "This prompt tells the model to categorize a book by using predefined categories.\n",
        "\n",
        "**Prompt**\n",
        "```\n",
        "Which category does The Odyssey belong to:\n",
        "- thriller\n",
        "- sci-fi\n",
        "- mythology\n",
        "- biography\n",
        "  ```\n",
        "\n",
        "**Response**\n",
        "```\n",
        "The answer: mythology\n",
        "\n",
        "Explanations:\n",
        "\n",
        "The Odyssey is an epic poem in ancient Greek literature. It is one of two major\n",
        "ancient Greek epic poems attributed to Homer. The Odyssey is an epic poem that\n",
        "tells the story of Odysseus, a Greek hero who fought in the Trojan War and then\n",
        "spent ten years trying to return home to Ithaca. The Odyssey is a work of\n",
        "mythology.\n",
        "```  \n",
        "\n",
        "The response is correct, but the model didn't stay within the bounds of the options. You also want to model to just respond with one of the options instead of in a full sentence. In this case, you can rephrase the instructions as a multiple choice question and ask the model to choose an option.\n",
        "\n",
        "**Prompt**\n",
        "\n",
        "```\n",
        "Multiple choice problem: Which of the following options describes the book The Odyssey?\n",
        "Options:\n",
        "- thriller\n",
        "- sci-fi\n",
        "- mythology\n",
        "- biography\n",
        "```\n",
        "\n",
        "**Response**\n",
        "```\n",
        "The answer is: mythology\n",
        "```"
      ],
      "metadata": {
        "id": "m9d9MXb9hGc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change the order of prompt content\n",
        "The order of the content in the prompt can sometimes affect the response. Try changing the content order and see how that affects the response.\n",
        "\n",
        "```\n",
        "Version 1:\n",
        "[examples]\n",
        "[context]\n",
        "[input]\n",
        "\n",
        "Version 2:\n",
        "[input]\n",
        "[examples]\n",
        "[context]\n",
        "\n",
        "Version 3:\n",
        "[examples]\n",
        "[input]\n",
        "[context]\n",
        "```"
      ],
      "metadata": {
        "id": "bzkgCBwqhsNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fallback responses\n",
        "\n",
        "A fallback response is a response returned by the model when either the prompt or the response triggers a safety filter. An example of a fallback response is \"I'm not able to help with that, as I'm only a language model.\"\n",
        "\n",
        "If the model responds with a fallback response, try increasing the temperature."
      ],
      "metadata": {
        "id": "eZlsAzWJM4Mk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Things to avoid\n",
        "\n",
        "- Avoid relying on models to generate factual information.\n",
        "- Use with care on math and logic problems."
      ],
      "metadata": {
        "id": "O0ADHp4JkC4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps\n",
        "- Now that you have a deeper understanding of prompt design, try writing your own prompts using Google AI Studio.\n",
        "- To learn about multimodal prompting, see the multimodal concepts overview."
      ],
      "metadata": {
        "id": "pSObgRsYkEFr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba3tYIzFYIUD"
      },
      "source": [
        "---\n",
        "If you made it this far, follow [David Regalado](https://beacons.ai/davidregalado) for more code!"
      ]
    }
  ]
}